{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KoBERT_NAVER.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMrL1F5LiT4mRpTSp1/HTzi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pINRwze3Nkny"},"source":["# KoBERT + NAVER 감정분석"]},{"cell_type":"markdown","metadata":{"id":"rNbQ0RIPE-E5"},"source":["*구글 BERT base multilingual cased의 한국어 성능 한계를 극복하고자 KoBERT를 활용*\n","\n","*Naver movie review 데이터를 활용하여 감정분석을 수행*"]},{"cell_type":"code","source":["# drive mount\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd gdrive/My Drive/Colab Notebooks/NAVER KoBERT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1e_pxc6jWmBq","executionInfo":{"status":"ok","timestamp":1640677607963,"user_tz":-540,"elapsed":2971,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"outputId":"40e79bce-f317-4800-826d-77b234521b55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/My Drive/Colab Notebooks/NAVER KoBERT\n"]}]},{"cell_type":"markdown","metadata":{"id":"LrwqPuAlNrWi"},"source":["## 1) 데이터\n"," - Naver sentiment movie corpus data\n","   - (https://github.com/e9t/nsmc/)"]},{"cell_type":"code","metadata":{"id":"tYWbgnMWJv4V"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import urllib.request"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OHnzhaDLOWwg","executionInfo":{"status":"ok","timestamp":1640677608369,"user_tz":-540,"elapsed":409,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4e3776b8-abde-423c-e2bb-fe094e34de41"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('ratings_test.txt', <http.client.HTTPMessage at 0x7f5b2f783950>)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"0r2lAL4cOaXJ"},"source":["train_data = pd.read_table('ratings_train.txt')\n","test_data = pd.read_table('ratings_test.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcr-FiKjOdBr","executionInfo":{"status":"ok","timestamp":1640677609197,"user_tz":-540,"elapsed":9,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/","height":224},"outputId":"feb35022-c4c9-4d2f-bc84-9972d875fe60"},"source":["print('훈련용 리뷰 개수 :',len(train_data)) # 훈련용 리뷰 개수 출력\n","train_data[:5] # 상위 5개 출력"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련용 리뷰 개수 : 150000\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-83705332-0ef4-425d-9bbc-1702be6327dc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83705332-0ef4-425d-9bbc-1702be6327dc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-83705332-0ef4-425d-9bbc-1702be6327dc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-83705332-0ef4-425d-9bbc-1702be6327dc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"FrzEUy87OghC","executionInfo":{"status":"ok","timestamp":1640677609198,"user_tz":-540,"elapsed":7,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/","height":224},"outputId":"6cdbbdce-2a50-43ec-cc6d-6a4b9e83309b"},"source":["print('테스트용 리뷰 개수 :',len(test_data)) # 테스트용 리뷰 개수 출력\n","test_data[:5]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["테스트용 리뷰 개수 : 50000\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-38752365-94de-4d59-ae19-432f92628f3e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6270596</td>\n","      <td>굳 ㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9274899</td>\n","      <td>GDNTOPCLASSINTHECLUB</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8544678</td>\n","      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6825595</td>\n","      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6723715</td>\n","      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38752365-94de-4d59-ae19-432f92628f3e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-38752365-94de-4d59-ae19-432f92628f3e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-38752365-94de-4d59-ae19-432f92628f3e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        id                                           document  label\n","0  6270596                                                굳 ㅋ      1\n","1  9274899                               GDNTOPCLASSINTHECLUB      0\n","2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n","3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n","4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["### 1-1) 데이터 전처리"],"metadata":{"id":"q5KdR1KGnA-8"}},{"cell_type":"code","metadata":{"id":"CYeWD9j0OjZy","executionInfo":{"status":"ok","timestamp":1640677609565,"user_tz":-540,"elapsed":373,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/","height":224},"outputId":"12df8ab6-7e7c-4e1d-a1c8-00e2333b8448"},"source":["train_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n","train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n","train_data['document'] = train_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n","train_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n","train_data = train_data.dropna(how='any') # Null 값 제거\n","print('전처리 후 훈련용 샘플의 개수 :',len(train_data))\n","train_data[:5]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["전처리 후 훈련용 샘플의 개수 : 145393\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-9bd62c29-2d7d-42bf-b725-e64e2ea4b554\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bd62c29-2d7d-42bf-b725-e64e2ea4b554')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9bd62c29-2d7d-42bf-b725-e64e2ea4b554 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9bd62c29-2d7d-42bf-b725-e64e2ea4b554');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["         id                                           document  label\n","0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n","1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"-WpM63bZOwoR","executionInfo":{"status":"ok","timestamp":1640677609566,"user_tz":-540,"elapsed":7,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/","height":224},"outputId":"a1fa3e83-450f-48c1-b5b0-40fa6553174e"},"source":["test_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n","test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n","test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n","test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n","test_data = test_data.dropna(how='any') # Null 값 제거\n","print('전처리 후 테스트용 샘플의 개수 :',len(test_data))\n","test_data[:5]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["전처리 후 테스트용 샘플의 개수 : 48852\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-278a48e6-603a-477f-a743-61a3bc40b32b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6270596</td>\n","      <td>굳 ㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8544678</td>\n","      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6825595</td>\n","      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6723715</td>\n","      <td>만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>7898805</td>\n","      <td>음악이 주가 된 최고의 음악영화</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-278a48e6-603a-477f-a743-61a3bc40b32b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-278a48e6-603a-477f-a743-61a3bc40b32b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-278a48e6-603a-477f-a743-61a3bc40b32b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        id                                   document  label\n","0  6270596                                        굳 ㅋ      1\n","2  8544678           뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n","3  6825595                  지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n","4  6723715  만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠      0\n","5  7898805                          음악이 주가 된 최고의 음악영화      1"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"IpFGt0WXCRZo"},"source":["- 영어의 알파벳들을 나타내는 정규 표현식은 [a-zA-Z]입니다.\n","\n","-  이 정규 표현식은 영어의 소문자와 대문자들을 모두 포함하고 있는 정규 표현식으로 이를 응용하면 영어에 속하지 않는 구두점이나 특수문자를 제거할 수 있습니다.\n","\n","- 위와 같은 원리를 한국어 데이터에 적용하고 싶다면, 우선 한글을 범위 지정할 수 있는 정규 표현식을 찾아내면 되겠습니다. \n","\n","- 일반적으로 자음의 범위는 ㄱ ~ ㅎ, 모음의 범위는 ㅏ ~ ㅣ와 같이 지정할 수 있습니다.\n"," - ㄱ ~ ㅎ: 3131 ~ 314E\n"," - ㅏ ~ ㅣ: 314F ~ 3163\n"," - (https://www.unicode.org/charts/PDF/U3130.pdf)\n","\n","- 또한 완성형 한글의 범위는 가 ~ 힣과 같이 사용합니다. \n"," - (https://www.unicode.org/charts/PDF/UAC00.pdf)"]},{"cell_type":"code","metadata":{"id":"vX45OPdVcRyI"},"source":["X_train = np.array(train_data['document'])\n","X_test = np.array(test_data['document'])\n","y_train = np.array(train_data['label'])\n","y_test = np.array(test_data['label'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1-2) Padding"],"metadata":{"id":"6syqp9Q9Y5Oh"}},{"cell_type":"code","source":["print('리뷰의 최대 길이 :',max(len(review) for review in X_train))\n","print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n","plt.hist([len(review) for review in X_train], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"metadata":{"id":"oibZnDEsjCao","executionInfo":{"status":"ok","timestamp":1640677609982,"user_tz":-540,"elapsed":421,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/","height":314},"outputId":"74574432-1bd1-4c19-8569-a6f8cdd856d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["리뷰의 최대 길이 : 140\n","리뷰의 평균 길이 : 33.08291320765099\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["def below_threshold_len(max_len, nested_list):\n","  count = 0\n","  for sentence in nested_list:\n","    if(len(sentence) <= max_len):\n","        count = count + 1\n","  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"],"metadata":{"id":"WPC9n-8ljMch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_len = 100\n","below_threshold_len(max_len, X_train)"],"metadata":{"id":"naRwFE68jNb_","executionInfo":{"status":"ok","timestamp":1640677609982,"user_tz":-540,"elapsed":5,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0fc538c8-6bba-4f05-bbb0-b79ba51de0b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 샘플 중 길이가 100 이하인 샘플의 비율: 94.86426444189198\n"]}]},{"cell_type":"markdown","metadata":{"id":"CJNA6TdMNw9D"},"source":["## 2) 모델 / Tokenizer 생성\n"," - KoBERT\n","  - (https://github.com/SKTBrain/KoBERT)"]},{"cell_type":"code","metadata":{"id":"KAiRAeVyNzjo","executionInfo":{"status":"ok","timestamp":1640677614648,"user_tz":-540,"elapsed":4670,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2857a166-5c3b-44c3-83f0-73302bb2f25c"},"source":["pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-_1270dy1/kobert-tokenizer_7540c52fecd5433eaba1df63da52e103\n","  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-_1270dy1/kobert-tokenizer_7540c52fecd5433eaba1df63da52e103\n"]}]},{"cell_type":"code","metadata":{"id":"glHOuJa2RILp"},"source":["#pip install torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LpNFMGlMQdpD","executionInfo":{"status":"ok","timestamp":1640677619075,"user_tz":-540,"elapsed":4433,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"50d3e3fb-52c1-4160-f661-5a6c6300dfe6"},"source":["pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"id":"mv52F1DVQpeR","executionInfo":{"status":"ok","timestamp":1640677623022,"user_tz":-540,"elapsed":3954,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d35f894-4c74-49bd-af1b-1fef36262dd0"},"source":["pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}]},{"cell_type":"code","metadata":{"id":"jv-ReKFPQkJ5","executionInfo":{"status":"ok","timestamp":1640677628850,"user_tz":-540,"elapsed":5831,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0cea82b-68b1-4924-d050-f634808be27e"},"source":["import torch\n","from transformers import BertForSequenceClassification\n","from kobert_tokenizer import KoBERTTokenizer\n","\n","model = BertForSequenceClassification.from_pretrained('skt/kobert-base-v1') # model 선언\n","tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1') # tokenizer 선언"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n"]}]},{"cell_type":"code","metadata":{"id":"y4Abri2FS1gi","executionInfo":{"status":"ok","timestamp":1640677632607,"user_tz":-540,"elapsed":3761,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"63e43676-9d57-449d-92e1-07287b80770d"},"source":["'''\n"," Tokenizer Test Example\n","'''\n","text = X_train[1] # X_train[1] : 흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나\t\n","\n","tokenized_text = tokenizer.tokenize(text)\n","print(tokenized_text)\n","\n","input_ids = tokenizer.encode(text)\n","print(input_ids)\n","\n","decoded_ids = tokenizer.decode(input_ids)\n","print(decoded_ids)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['▁', '흠', '포', '스터', '보고', '▁초', '딩', '영화', '줄', '오', '버', '연', '기', '조차', '▁', '가', '볍', '지', '▁않', '구나']\n","[2, 517, 7989, 7728, 6686, 6366, 4501, 5957, 6954, 7292, 6964, 6323, 6928, 5561, 7261, 517, 5330, 6359, 7318, 3146, 5496, 3]\n","[CLS] 흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나[SEP]\n"]}]},{"cell_type":"code","metadata":{"id":"Eo6BW3_BVVKn","executionInfo":{"status":"ok","timestamp":1640677632608,"user_tz":-540,"elapsed":7,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a6105643-7f01-496b-89d7-d92941415e7c"},"source":["'''\n"," Model Test Example\n","'''\n","inputs = tokenizer.batch_encode_plus([text], return_tensors='pt')\n","\n","out = model(**inputs)\n","\n","print(out.loss)\n","print(out.logits)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n","tensor([[-0.1131,  0.0938]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"O5clA_knN0NR"},"source":["## 3) 모델 학습"]},{"cell_type":"code","source":["import datetime\n","\n","# 시간 표시 함수\n","def format_time(elapsed):\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"zGvRJKg9cBaj"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FUAUB7kygSC_"},"source":["from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n"," \n","#  Returns a bool indicating if CUDA is currently available.\n","print(torch.cuda.is_available())\n","#  True\n"," \n","#  Returns the index of a currently selected device.\n","print(torch.cuda.current_device())\n","#  0\n"," \n","#  Returns the number of GPUs available.\n","print(torch.cuda.device_count())\n","#  1\n"," \n","#  Gets the name of a device.\n","print(torch.cuda.get_device_name(0))\n","#  'Tesla P100-PCIE-16GB'\n"," \n","#  Context-manager that changes the selected device.\n","#  device (torch.device or int) – device index to select. \n","print(torch.cuda.device(0))"],"metadata":{"id":"zMW6kG0p7P74","executionInfo":{"status":"ok","timestamp":1640677632609,"user_tz":-540,"elapsed":6,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"75b23553-5b28-4b65-f9c2-220fc56b890c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","0\n","1\n","Tesla P100-PCIE-16GB\n","<torch.cuda.device object at 0x7f59b70ecd90>\n"]}]},{"cell_type":"code","metadata":{"id":"M_bCHDdjN2tj"},"source":["class NsmcDataset(Dataset):\n","    ''' Naver Sentiment Movie Corpus Dataset '''\n","    def __init__(self, df):\n","        self.df = df\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        text = self.df.iloc[idx, 1]\n","        label = torch.tensor(self.df.iloc[idx, 2])\n","        return text, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cuda empty cache\n","import gc\n","gc.collect()\n","torch.cuda.empty_cache()"],"metadata":{"id":"Kx45td_XSGP_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3-1) train"],"metadata":{"id":"Gx0665UamW2E"}},{"cell_type":"code","metadata":{"id":"B5MQ-lvXgbOO"},"source":["from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","import time\n","\n","# hyperparameter\n","epochs = 1\n","learning_rate = 2e-5\n","batch = 50\n","\n","itr = 1\n","p_itr = 100\n","total_loss = 0\n","total_len = 0\n","total_correct = 0\n","\n","# dataloader 선언\n","nsmc_train_dataset = NsmcDataset(train_data)\n","train_loader = DataLoader(nsmc_train_dataset, batch_size=batch, shuffle=True, num_workers=2)\n","\n","# optimizer 선언\n","optimizer = AdamW(model.parameters(),\n","                 lr=learning_rate,\n","                 eps=1e-8\n","                 )\n","\n","# 총 훈련 스텝\n","total_steps = len(train_loader) * epochs\n","# lr 스케줄러\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","# CUDA device\n","cuda = torch.device('cuda')\n","model = model.cuda()\n","\n","model.train()\n","for epoch in range(epochs):\n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n","    print('Training...')\n","        \n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # iteration 초기화\n","    itr = 1\n","    \n","    for text, label in train_loader:\n","        optimizer.zero_grad()\n","        \n","        # encoding and zero padding\n","        sample = tokenizer.batch_encode_plus(text, padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n","        \n","        sample, label = sample.to(device=cuda), label.to(device=cuda)\n","\n","        # forward\n","        outputs = model(**sample, labels=label)\n","\n","        logits = outputs['logits']\n","        loss = outputs['loss']\n","\n","        # get loss\n","        pred = torch.argmax(F.softmax(logits, dim=1), dim=1)\n","        correct = pred.eq(label)\n","\n","        total_correct += correct.sum().item()\n","        total_len += len(label)\n","        total_loss += loss.item()\n","\n","        # update gradient\n","        loss.backward()\n","\n","        optimizer.step()\n","        scheduler.step()\n","        \n","        # print acc\n","        if itr % p_itr == 0:\n","          elapsed = format_time(time.time() - t0)\n","          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.   Train Loss: {:.4f}. Accuracy: {:.3f}.'.format(itr, len(train_loader), elapsed, total_loss/p_itr, total_correct/total_len))\n","          total_loss = 0\n","          total_len = 0\n","          total_correct = 0\n","\n","        itr+=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3-2) evaluation"],"metadata":{"id":"1I_TY6nmmf90"}},{"cell_type":"code","metadata":{"id":"37G-jphQho3f"},"source":["# dataloader 선언\n","nsmc_eval_dataset = NsmcDataset(test_data)\n","eval_loader = DataLoader(nsmc_eval_dataset, batch_size=50, shuffle=False, num_workers=2)\n","\n","total_loss = 0\n","total_len = 0\n","total_correct = 0\n","\n","# CUDA device\n","cuda = torch.device('cuda')\n","model = model.cuda()\n","\n","model.eval()\n","for text, label in eval_loader:\n","   # encoding and zero padding\n","    sample = tokenizer.batch_encode_plus(text, padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n","    \n","    sample, label = sample.to(device=cuda), label.to(device=cuda)\n","    \n","    # forward\n","    outputs = model(**sample, labels=label)\n","\n","    logits = outputs['logits']\n","    \n","    #get accuracy\n","    pred = torch.argmax(F.softmax(logits, dim=1), dim=1)\n","    correct = pred.eq(label)\n","    total_correct += correct.sum().item()\n","    total_len += len(label)\n","\n","print('Test accuracy: ', total_correct / total_len)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 저장\n","PATH='/content/gdrive/My Drive/Colab Notebooks/NAVER KoBERT/model.pt'\n","torch.save(model.state_dict(), PATH)"],"metadata":{"id":"B72REEdy9NkY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v_bQpnIyN3Sp"},"source":["\n","## 4) 테스트"]},{"cell_type":"code","source":["# 모델 불러오기\n","PATH='/content/gdrive/My Drive/Colab Notebooks/NAVER KoBERT/model_epoch5.pt'\n","model = BertForSequenceClassification.from_pretrained('skt/kobert-base-v1')\n","model.load_state_dict(torch.load(PATH))\n","model.eval()"],"metadata":{"id":"g-dZQ5meXUFQ","executionInfo":{"status":"ok","timestamp":1640677643287,"user_tz":-540,"elapsed":9751,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a2beb3d-86f8-48a7-9e0c-db3a923b697d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"eaQ_gviWN5fa"},"source":["def test_sentences(new_sentence):\n","    new_sentence = new_sentence.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n","    new_sentence = tokenizer.batch_encode_plus([new_sentence], return_tensors='pt')\n","    \n","    # 예측\n","    with torch.no_grad():\n","      outputs = model(**new_sentence)\n","    \n","    logits = outputs['logits']\n","    \n","    pred = torch.argmax(logits, dim=1)\n","    score = F.softmax(logits, dim=1)\n","    score = (score[0][pred]).item()\n","\n","    # print result\n","    if(pred > 0.5):\n","      print(\"{:2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n","    else:\n","      print(\"{:2f}% 확률로 부정 리뷰입니다.\\n\".format(score * 100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TD8whZoOiBzm","executionInfo":{"status":"ok","timestamp":1640677933817,"user_tz":-540,"elapsed":494,"user":{"displayName":"김태수","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03924027973000690944"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c79b3c27-dfd9-458e-8184-375005c9b641"},"source":["test_sentences('이 영화 꿀잼 ㅋㅋㅋ')\n","test_sentences('이 영화 노잼 ㅋㅋㅋ')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["98.787200% 확률로 긍정 리뷰입니다.\n","\n","99.915826% 확률로 부정 리뷰입니다.\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"4WifJ7XfE42I"},"source":["#### reference\n","\n","- https://wikidocs.net/44249\n","- https://github.com/SKTBrain/KoBERT/tree/master/kobert_hf\n","- https://velog.io/@kimhwangdae/Week9-Huggingface\n","- https://yonghyuc.wordpress.com/2019/08/06/pytorch-cuda-gpu-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/\n","- http://yonghee.io/bert_binary_classification_naver/"]}]}